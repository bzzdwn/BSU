\documentclass[a4paper, 12pt]{article}
\usepackage{cmap}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{upgreek}
\usepackage{setspace}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[normalem]{ulem}
\usepackage{mathtext} % русские буквы в формулах
\usepackage[left=2cm,right=2cm, top=2cm,bottom=2cm,bindingoffset=0cm]{geometry}
\usepackage[english,russian]{babel}
\newenvironment{Proof} % имя окружения
{\par\noindent{$\blacklozenge$}} % команды для \begin
{\hfill$\scriptstyle\boxtimes$}
\newcommand{\Rm}{\mathbb{R}}
\newcommand{\Cm}{\mathbb{C}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\N}{\mathbb{N}}
\newtheorem*{theorem}{Теорема}
\newtheorem*{cor}{Следствие}
\newtheorem*{lem}{Лемма}
\newcommand{\FI}{\text{Ф}}
\newcommand{\Ln}{L_n = D^n + a_{n-1}D^{n-1} + \ldots + a_1D + a_0D^0}
\begin{document}
	\section*{Метод Эйлера построения ФСР СтЛВУ.}
	Перенесем СтЛОУ некоторые необходимые нам определения.\\ 
	Рассмотрим стационарное линейное векторное уравнение 
	$$DX = AX, \quad t \in \Rm.\eqno(1)$$
	Множество решений системы (1) является \textbf{векторным пространством}.\\\\
	$\bullet$ \textit{Пусть $X_1(t) = \begin{pmatrix}
			x_{11}(t)\\\vdots\\x_{n1}(t)
		\end{pmatrix}$, $\ldots$, $X_n(t) = \begin{pmatrix}
			x_{1n}(t)\\\vdots\\x_{nn}(t)
		\end{pmatrix}$ --- некоторые векторные функции.
		Определитель $$W(t) = \begin{vmatrix}
			x_{11}(t) & \dots & x_{1n}(t)\\
			\vdots & \ddots & \vdots\\
			x_{n1}(t) & \dots & x_{nn}(t)\\
		\end{vmatrix}$$ называется \textbf{определителем Вронского} системы $X_1,\ldots,X_n$.}\\\\
		Если векторные функции  $X_1,\ldots,X_n$ линейно зависимы, то их $W(t) = 0$ $\forall t$.\\\\
		Если система решений уравнения $(1)$ линейно независимая, то их $W(t) \ne 0$ $\forall t$.\\\\
	Рассмотрим $n$ задач Коши $DX = AX$, $X|_{t=t_0} = E_i$, где $E_i$ --- $i$-ый столбец единичной матрицы $E = [E_1,\ldots, E_n]$. По теореме о существовании и единственности решения задачи Коши все эти задачи Коши имеют единственные решения $X_1(t),\ldots,X_n(t)$, которые являются линейно независимыми и образуют базис пространства решений (ФСР) системы (1). Таким образом, общее решение имеет вид $$X_{\text{OP}}(t) = C_1X_1 + \ldots + C_nX_n,\quad \forall C_i \in \Rm.$$
	$\bullet$ \textit{Матрица $\FI(t) = [X_1(t),\ldots,X_n(t)]$ называется \textbf{фундаментальной матрицей (ФМ)} системы $(1)$.}\\\\
	Тогда общее решение уравнения (1) в матричном виде может быть записано следующим образом: $$X_{\text{OP}}(t) = \FI(t)\cdot C, \quad \forall C \in \Rm_{n,1}.$$
	Теперь рассмотрим метод Эйлера, который непосредственно позволяет нам построить ФМ.\\\\
	Запишем решение уравнения в виде $X(t) = Be^{\lambda t}$, где $B$ --- собственный вектор, а $\lambda$ --- собственное значение матрицы $A$, так как, подставив решение в уравнение $(1)$, получим СЛАУ $(A-\lambda E)B = 0$. Используя жорданов базис матрицы $A$, составленный из жордановых цепочек $B_0, \ldots, B_k$, можно построить $n$ различных решений уравнения (1). Тогда матрица составленная из этих решений образует фундаментальную матрицу.\\\\
	Таким образом, нахождение ФСР и построение ФМ сводится к построению жорданова базиса матрицы $A$, то есть нахождению собственных векторов этой матрицы. Подробнее с построением собственных векторов ознакомиться в разделах Линейной Алгебры "Линейные операторы" (собственные векторы и значения) и "Полиномиальные матрицы" (построение жорданова базиса).\\\\
	Для освежения в памяти рассмотрим один пример с подробным нахождением собственных векторов. Далее будем ссылаться на то, что читатель уже умеет находить собственные векторы матрицы.\\\\
	\textbf{Пример 1}. Построить базис пространства решений уравнения $$DX = AX, \quad A = \begin{pmatrix}
		2 & 0 & 0\\
		1 & 1 & 0\\
		1 & -1 & 3
	\end{pmatrix}.$$
\textbf{Решение.} Построим характеристическую матрицу $A - \lambda E$ и найдем с помощью нее характеристический многочлены матрицы $A$, который равен $\det (A - \lambda E)$:
$$\det(A - \lambda E) = \begin{vmatrix}
	2 - \lambda & 0 & 0\\
	1 & 1-\lambda & 0\\
	1 & -1 & 3 - \lambda
\end{vmatrix} = -(\lambda - 2)(\lambda-1)(\lambda -3).$$
Таким образом, собственными значениями матрицы $A$ являются $\lambda_1 = 1$, $\lambda_2 = 2$, $\lambda_3 = 3$, $k_{1,2,3} = 1$. Следовательно, каждому собственному значению соответствует жорданова клетка размера 1, то есть каждое значение имеет ровно 1 собственный вектор. Найдем их:
\begin{enumerate}
	\item $$A - E = \begin{pmatrix}
		1 & 0 & 0\\
		1 & 0 & 0\\
		1 & -1 & 2
	\end{pmatrix}\sim \begin{pmatrix}
	1 & 0 & \vline & 0\\
	0 & 1 & \vline & -2
\end{pmatrix}.$$ Возьмем третий столбец в качестве свободной переменной и обозначим его за $\alpha$. Тогда фундаментальная система решений $A - E$ равна $(0, 2\alpha, \alpha)$, собственный вектор матрицы равен $(0,2,1)$. Тогда по формуле $X(t) = Be^{\lambda t}$ введенной ранее решение уравнения записывается как $$x_1(t) = e^t(0,2,1)^T.$$
\item $$A - 2E = \begin{pmatrix}
	0 & 0 & 0\\
	1 & -1 & 0\\
	1 & -1 & 1
\end{pmatrix}\sim \begin{pmatrix}
1 & \vline & -1 & \vline & 0\\
0 & \vline & 0 & \vline & 1\\
\end{pmatrix}.$$ Возьмем второй столбец в качестве свободной переменной. Тогда собственный вектор равен $(1,1,0)$. А соответствующее ему линейно независимое векторного уравнения имеет вид
$$x_2(t) = e^{2t}(1,1,0)^T.$$
\item $$A - 3E = \begin{pmatrix}
	-1 & 0 & 0\\
	1 & -2 & 0\\
	1 & -1 & 0
\end{pmatrix} \sim \begin{pmatrix}
1 & 0 & \vline & 0\\
0 & 1 & \vline & 0
\end{pmatrix}.$$ Таким образом, $$x_3(t) = e^{3t}(0,0,1)^T.$$
\end{enumerate}
Мы нашли все столбцы, которые образуют ФСР. Следовательно, теперь мы можем построить искомую фундаментальную матрицу 
$$\FI(t) = \begin{pmatrix}
	0 & e^{2t} & 0\\
	2e^t & e^{2t} & 0\\
	e^t & 0 & e^{3t}
\end{pmatrix}.$$ 
Заметим, что общее решение исходного уравнения будет иметь вид $$X_\text{oo} = \FI(t)\cdot C =  \begin{pmatrix}
	0 & e^{2t} & 0\\
	2e^t & e^{2t} & 0\\
	e^t & 0 & e^{3t}
\end{pmatrix} \cdot \begin{pmatrix}
C_1 \\ C_2\\ C_3
\end{pmatrix}.$$
Также заметим, что данное СтЛВУ мы рассматривали в качестве первого примера прошлом уроке. Вы можете самостоятельно перемножить матрицы в последнем уравнении и сравнить с прошлым уроком.\\\\
\textit{Дополнительно}: докажите, что полученные решения действительно являются линейно независимыми.\\\\
\textbf{Ответ:} $\FI(t) = \begin{pmatrix}
	0 & e^{2t} & 0\\
	2e^t & e^{2t} & 0\\
	e^t & 0 & e^{3t}
\end{pmatrix}.$\\\\
\textbf{Замечание.} \textit{Отличительной чертой такого метода нахождения решения СтЛВУ от рассмотренных в прошлом уроке является своего рода "отсутствие взаимодействия"\ с оператором дифференцирования. Мы работаем лишь с матрицей $A$, не занимаясь вычислением производных или интегралов.}\\\\
На данном этапе можно было бы и закончить текущий урок. Однако не всё так просто. Мы рассмотрели лишь случай, при котором матрица $A$ имеет собственные значения, \textbf{геометрическая кратность} которых \textbf{совпадает с алгебраической}. В этом случае все СтЛВУ решаются аналогичным обраом.\\\\ Теперь же рассмотрим случай, когда \textbf{алгебраическая и геометрическая кратности собственного значения не совпадают}. Геометрическая кратность соответствует количеству линейно независимых рещений $x(t)$, соответствующих собственному значению $\lambda$. И в случае, когда алгебраическая кратность $k$ больше, чем геометрическая кратность $r$, нам необходимо дополнить совокупность линейно независимыми решениями вида $$x(t) = (\alpha_0 + \alpha_1t + \ldots + \alpha_mt^m)e^{\lambda t},$$ где $\alpha_i$ --- векторы, а $m = \overline{1,r - k}$.\\\\
То есть, если нам необходимо найти одно независимое решение, то оно имеет вид $$x_1(t) = (\alpha_0 + \alpha_1t)e^{\lambda t}.$$
Если нужно найти второе решение, то оно будет иметь вид
$$x_2(t) = (\beta_0 + \beta_1t + \beta_2t^2)e^{\lambda t}.$$
И так далее.\\\\
\textbf{Пример 2.} Найти общее решение уравнения $$DX = AX, \quad A = \begin{pmatrix}
	-1 & 0 & 1\\
	0 & 2 & 0\\
	-1 & 0 & -3
\end{pmatrix}.$$
\textbf{Решение.} Матрица $A$ имеет собственные значения равные $\lambda_1 = -2$, $k_1 = 2$; $\lambda_2 = 2$. \begin{enumerate}
	\item Найдем геометрическую кратность собственного значения $-2$:
	$r_1 = n - rank(A + 2E) = 3 - rank\begin{pmatrix}
		1 & 0 & 1\\
		0 & 4 & 0\\
		-1 & 0 & -1
	\end{pmatrix} = 1.$
	Следовательно, $r_1 < k_1$, значит, мы сможем найти один собственный вектор $$x_1(t) = e^{-2t}(-1, 0, 1)^T$$ путем решения СЛАУ $A+ 2E = 0$. В качестве второго собственного вектора возьмем $x_2(t) = (\alpha_0 + \alpha_1t)e^{-2t}$. Найдем векторы $\alpha_0$, $\alpha_1$. Подставим $x_2(t)$ в уравнение $DX = AX$, так как он является решением, получим $$D((\alpha_0 + \alpha_1t)e^{-2t}) = A(\alpha_0 + \alpha_1t)e^{-2t};$$
	$$(-2\alpha_0 + \alpha_1 - 2\alpha_1 t)e^{-2t} = A(\alpha_0 + \alpha_1t)e^{-2t}.$$
	Приравняем коэффициенты при соответствующих степенях $t$:
	$$-2\alpha_1 = A\alpha_1 \Longleftrightarrow (A + 2E) \alpha_1 = 0.$$
	А данную СЛАУ мы уже решили ранее, когда искали $x_1(t)$, то есть $\alpha_1 = (-1, 0, 1)$.
	$$-2\alpha_0 + \alpha_1 = A\alpha_0\Longleftrightarrow (A+2)\alpha_0 = \alpha_1.$$
	Полученную СЛАУ решим методом Гаусса:
	$$\begin{pmatrix}
		1 & 0 & 1 & \vline & -1\\
		0 & 4 & 0 &\vline & 0\\
		-1 & 0 & -1 & \vline & 1\\
	\end{pmatrix}\sim \begin{pmatrix}
		1 & 0 & 1 & \vline & -1\\
		0 & 1 & 0 &\vline & 0
	\end{pmatrix}.$$ Если $\alpha_0(\upgamma_1, \upgamma_2, \upgamma_3)$, то $\upgamma_1 = -1 - \upgamma_3$, $\upgamma_2 = 0$. Таким образом, $\alpha_0 = (-1, 0, 0)$. Полученные $\alpha_i$ подставим в $x_2(t)$ и получим $$x_2(t) = e^{-2t}(-t-1, 0, t)^T.$$
\item Для собственного значения $\lambda_2 = 2$ найдем собственный вектор аналогично предыдущему примеру:
$$A-2E = \begin{pmatrix}
	-3 & 0 & 1\\
	0 & 0 & 0\\
	-1 & 0 & -5
\end{pmatrix}\sim \bordermatrix{
& & \alpha &\cr
&1 & 0 & 0\cr
&0 & 0 &  1\cr
}.$$ Тогда $$x_3(t) = e^{2t}(0,1,0)^T.$$
\end{enumerate}
Мы нашли ФСР $(x_1(t), x_2(t), x_3(t))$, теперь можем построим ФМ:
$$\FI(t) = \begin{pmatrix}
	-e^{-2t} & (-t-1)e^{-2t} & 0\\
	0 & 0 & e^{2t}\\
	e^{-2t} & te^{-2t} & 0
\end{pmatrix}.$$
И общее решение исходного СтЛВУ имеет вид
$$X(t) = \begin{pmatrix}
	-e^{-2t} & (-t-1)e^{-2t} & 0\\
	0 & 0 & e^{2t}\\
	e^{-2t} & te^{-2t} & 0
\end{pmatrix} \cdot \begin{pmatrix}
C_1\\C_2\\C_3
\end{pmatrix}.$$
\textbf{Ответ:} $X(t) = \begin{pmatrix}
	-e^{-2t} & (-t-1)e^{-2t} & 0\\
	0 & 0 & e^{2t}\\
	e^{-2t} & te^{-2t} & 0
\end{pmatrix} \cdot \begin{pmatrix}
	C_1\\C_2\\C_3
\end{pmatrix}.$\\\\
\textbf{Пример 3.} Найти общее решение уравнения $$DX = AX, \quad A = \begin{pmatrix}
	-2 & 0 & -1\\
	3 & -3 & 5\\
	2 & -1 & 2
\end{pmatrix}.$$
\textbf{Решение.} Собственное значение матрицы $\lambda = -1$, $k = 3$. Найдем геометрическую кратность. Она равна $r = 1$. Следовательно, для построения ФСР мы найдем один собственный вектор и дополним его двумя независимыми. Найдем собственный вектор:
$$A + E = \begin{pmatrix}
	-1 & 0 & -1\\
	3 & -2 & 5\\
	2 & -1 & 3
\end{pmatrix}\sim \begin{pmatrix}
1 & 0 & \vline & 1\\
0 & 1 & \vline & -1
\end{pmatrix}.$$
Возьмем в качестве свободной переменной третий столбец и получим собственный вектор $(-1, 1, 1)$ и $$x_1(t) = e^{-t}(-1, 1, 1)^T.$$
В качестве дополнения возьмем векторы $x_2(t) = e^{-t}(\alpha_0 + \alpha_1t)$ и $x_3(t) = (\beta_0 + \beta_1t + \beta_2t^2)$.\\
Найдем $x_2(t)$ аналогично предыдущему примеру, то есть подставим в уравнение $DX = AX$:
$$(\alpha_0 - \alpha_1t + \alpha_1)e^{-t} = A(\alpha_0 +\alpha_1t)e^{-t}.$$
Снова приравниваем коэффициенты при соответствующих степенях $t$ и получаем $\alpha_1(-1, 1, 1)$; $(A+E)\alpha_0 = \alpha_1$:
$$\begin{pmatrix}
	-1 & 0 & -1 & \vline & -1\\
	3 & -2 & 5 & \vline & 1\\
	2 & -1 & 3 & \vline & 1
\end{pmatrix}\sim \begin{pmatrix}
1 & 0 & 1 & \vline & 1\\
0 & 1 & -1 & \vline & 1
\end{pmatrix}.$$
Таким образом, $\alpha_0(1,1,0)$ и $$x_2(t)=e^{-t}(1-t, 1+t, t)^T.$$
Так же найдем и вектор $x_3(t)$:
$$(-\beta_0 - \beta_1 t - \beta_2 t^2 + \beta_1 + 2\beta_2t)e^{-t} = A(\beta_0 + \beta_1t + \beta_2t^2)e^{-t}.$$
Отсюда $\beta_2(-1, 1, 1)$; $(A+E)\beta_1 = 2\beta_2$:
$$\begin{pmatrix}
	-1 & 0 & -1 & \vline & -2\\
	3 & -2 & 5 & \vline & 2\\
	2 & -1 & 3 & \vline & 2
\end{pmatrix}\sim \begin{pmatrix}
	1 & 0 & 1 & \vline & 2\\
	0 & 1 & -1 & \vline & 2
\end{pmatrix}\Rightarrow \beta_1(2,2,0)$$ и $(A+E)\beta_0 = \beta_1$:  $$\begin{pmatrix}
-1 & 0 & -1 & \vline & 2\\
3 & -2 & 5 & \vline & 2\\
2 & -1 & 3 & \vline & 0
\end{pmatrix}\sim \begin{pmatrix}
1 & 0 & 1 & \vline & -2\\
0 & 1 & -1 & \vline & -4
\end{pmatrix}\Rightarrow \beta_0(-2,-4,0).$$
Подставим полученные $\beta_i$ в $x_3(t)$ и получим $$x_3(t) = e^{-t}(-2+2t-t^2, -4+2t+t^2, t^2)^T.$$
Теперь составим из найденной ФСР фундаментальную матрицу и найдем общее решние СтЛВУ
$$\FI(t) = e^{-t}\begin{pmatrix}
	-1 & 1-t & -2+2t-t^2\\
	1& 1+t & -4 + 2t + t^2\\
	1 & t & t^2
\end{pmatrix}.$$
$$X(t) = e^{-t}\begin{pmatrix}
	-1 & 1-t & -2+2t-t^2\\
	1& 1+t & -4 + 2t + t^2\\
	1 & t & t^2
\end{pmatrix} \cdot \begin{pmatrix}
C_1\\C_2\\C_3
\end{pmatrix}.$$
\textbf{Ответ:} $X(t) = e^{-t}\begin{pmatrix}
	-1 & 1-t & -2+2t-t^2\\
	1& 1+t & -4 + 2t + t^2\\
	1 & t & t^2
\end{pmatrix} \cdot \begin{pmatrix}
	C_1\\C_2\\C_3
\end{pmatrix}.$\\\\
Также для поиска решений в матрице с одним и больше собственными значениями геометрической кратности меньше, чем алгебраической, можно воспользоваться теоремой.
\begin{theorem}
	Если $B_0, B_1, \ldots, B_k$ --- жорданова цепочка матрицы $A$, соответствующая собственному значению $\lambda_0$, то векторная функция $$X(t) = (B_0\dfrac{t^k}{k!} + B_1\dfrac{t^{k-1}}{(k-1)!} + B_2\dfrac{t^{k-2}}{(k-2)!} + \ldots + B_{k-1}\dfrac{t}{1!} + B_k)e^{\lambda_0 t}$$ является решением уравнения $(1)$. 
\end{theorem}
Где жорданова цепочка --- это собственные векторы и присоединенные к ним линейно независимые векторы, соответствующие одному собственному значению $\lambda_0$. Рассмотрим пример, где найдем решения таким способом. Подробнее данный пример рассмотрен в матричном методе (Пример 6).\\\\
\textbf{Пример 5.} Найти общее решение уравнения $DX = AX$, где $$A = \begin{pmatrix}
	4 & 5 & -2\\
	-2 & -2 & 1\\
	-1 & -1 & 1
\end{pmatrix}.$$
\textbf{Решение.} Матрица имеет одно собственное значение $\lambda = 1$ алгебраической кратности $k = 3$ и геометрической кратности $r = 1$. Следовательно, собственному значению соответствует один собственный вектор.
Теперь найдем собственный вектор, соответствующий собственному значению $$A - E = \begin{pmatrix}
	3 & 5 & -2\\
	-2 & -3 & 1\\
	-1 & -1 & 0
\end{pmatrix}\sim \begin{pmatrix}
	1 & \vline & 1 & \vline & 0\\
	0 & \vline & -1 &\vline & 1
\end{pmatrix}.$$
В качестве свободной переменной возьмем второй столбец. Тогда ФСР имеет вид $(-\alpha, \alpha, \alpha)$, а собственный вектор $$B_0(1, -1, -1).$$
Теперь займемся поиском присоединенных векторов. Для поиска присоединенного к $a_1$ решим СЛАУ $(A-E\ |\ a_1)\upgamma = 0$:
$$(A-E\ |\ a_1) = \begin{pmatrix}
	3 & 5 & -2 & \vline & 1\\
	-2 & -3 & 1 & \vline & -1\\
	-1 & -1 & 0 & \vline & -1
\end{pmatrix}\sim \begin{pmatrix}
	1 & 1 & 0 & \vline & 1\\
	0 & -1 & 1 & \vline & 1\\
\end{pmatrix}.$$
Возьмем в качестве свободной переменной второй столбец. Тогда ФСР имеет вид $(1 - \alpha, \alpha, 1 + \alpha)$ и собственный вектор $$B_1(1,0,1).$$
Осталось найти последний присоединенный вектор. Искать мы его будем для вектора $a_2$:
$$(A-E\ |\ a_2) = \begin{pmatrix}
	3 & 5 & -2 & \vline & 1\\
	-2 & -3 & 1 & \vline & 0\\
	-1 & -1 & 0 & \vline & 1
\end{pmatrix}\sim\begin{pmatrix}
	1 & 1 & 0 & \vline & -1\\
	0 & -1 & 1 & \vline & -2\\
\end{pmatrix}.$$
Снова возьмем второй столбец в качестве свободной переменной и получим ФСР $(-1-\alpha, \alpha, -2 + \alpha)$ и собственный вектор 
$$B_3(-1, 0, -2).$$
Тогда при $k = 0$ по формуле из теоремы получаем решение
$$x_1(t) = e^{t}(1,-1,-1).$$
При $k =1$ получаем
$$x_2(t) = e^{t}(t + 1,-t,-t + 1).$$
При $k=2$ аналогично
$$x_3(t) = e^{t}\Big(\frac{t^2}{2} + t - 1,-\frac{t^2}{2},-\frac{t^2}{2} + t - 2\Big).$$
Таким образом, общее решение СтЛВУ имеет вид $$X(t) =e^t\begin{pmatrix}
	1 & t+1 & \frac{t^2}{2} + t - 1\\
	-1 & -t & -\frac{t^2}{2}\\
	-1 & 1-t & -\frac{t^2}{2} + t - 2
\end{pmatrix}\begin{pmatrix}
	C_1\\C_2\\C_3
\end{pmatrix}.$$
\textbf{Ответ:} $X(t) =e^t\begin{pmatrix}
	1 & t+1 & \frac{t^2}{2} + t - 1\\
	-1 & -t & -\frac{t^2}{2}\\
	-1 & 1-t & -\frac{t^2}{2} + t - 2
\end{pmatrix}\begin{pmatrix}
	C_1\\C_2\\C_3
\end{pmatrix}.$\\\\
\textbf{Замечание}. \textit{Причем, если обратимся к матричному методу, можно проследить, что полученная в ходе решения фундаментальная матрица $\FI(t) = Se^{Jt}$, но нормированной она не будет.}\\\\
\textbf{Пример 5.} Найти общее решение уравнения $$DX = AX, \quad A = \begin{pmatrix}
	2 & -4\\
	1 & 2
\end{pmatrix}.$$
\textbf{Решение.} Матрица $A$ имеет комплексные собственные значения $\lambda_1 = 2-2i$, $\lambda_2 = 2+2i$, которым соответствуют собственные векторы $a_1(-2i, 1)$, $a_2(2i, 1)$. Далее стоит учесть одно важдное замечание.\\\\
\textbf{Замечание.} \textit{Если среди собственных значений матрицы $A$ существуют мнимые, то собственные и присоединенные векторы, соответствующие этим собственным значениям, также мнимые. Но так как матрица $A$ действительная, их действительные и мнимые части являются линейно независимыми действительными решениями. Следовательно, используя комплексное собственное значение кратности $k$ можно построить $2k$ линейно независимых действительных решений. При этом аналогично построенные решения для сопряженного мнимого значения \textbf{новыми} независимыми решениями \textbf{не являются}.} \\\\
Из этого следует, что собственному значению $2+ 2i$ соответствует комплекснозначная функция $x_1(t) = e^{2+2i}(2i, 1)^T = \begin{pmatrix}
	2ie^{2t}cos(2t) -2e^{2t}sin(2t)\\
	e^{2t}cos(2t) + ie^{2t}sin(2t)
\end{pmatrix}$. В таком случае действительными линейно независимыми решениями являются столбцы $$Re(x_1(t)) = \begin{pmatrix}
-2e^{2t}sin(2t)\\
e^{2t}cos(2t)
\end{pmatrix}, \quad Im(x_1(t)) = \begin{pmatrix}
2e^{2t}cos(2t)\\
e^{2t}sin(2t)
\end{pmatrix}.$$
Из замечания следует, что данные решения соответствуют как $\lambda_1$, так и $\lambda_2$. То есть эти векторы и образуют ФСР. Тогда фундаментальная матрица имеет вид
$$\FI(t) = \begin{pmatrix}
	-2e^{2t}sin(2t) & 2e^{2t}cos(2t)\\
	e^{2t}cos(2t) & e^{2t}sin(2t)
\end{pmatrix}.$$
Тогда общее решение имеет вид $$X(t) = \begin{pmatrix}
	-2e^{2t}sin(2t) & 2e^{2t}cos(2t)\\
	e^{2t}cos(2t) & e^{2t}sin(2t)
\end{pmatrix}\cdot \begin{pmatrix}
C_1\\C_2
\end{pmatrix}.$$
\textbf{Ответ:} $X(t) = \begin{pmatrix}
	-2e^{2t}sin(2t) & 2e^{2t}cos(2t)\\
	e^{2t}cos(2t) & e^{2t}sin(2t)
\end{pmatrix}\cdot \begin{pmatrix}
	C_1\\C_2
\end{pmatrix}.$\\\\
Сделаем небольшой вывод нахождении решения СтЛВУ методом Эйлера: если стоит задача построить ФСР или найти общее решение однородного СтЛВУ, то
\begin{itemize}
	\item для матрицы $A$ строим характеристический многочлен и находим собственные значения;
	\item если для собственных значений геометрические кратности  совпадают с алгебраическими, то для каждого собственного значения находим собственный вектор;
	\item если для собственных значений геометрические кратности  совпадают с алгебраическими, то для этих собственных значений строим дополнительные $k-r$ линейно независимых решений, зависящих от $t$.
	\item если собственные значения являются мнимыми, то одному собственному значению кратности $k$ соответствует $2k$ действительных линейно независимых решений, которые являются действительной и мнимой частями комплексного линейно независимого решения $x(t)$, соответствующего этому собственному значению;
	\item строим ФСР и фундаментальную матрицу;
	\item произведение фундаментальной матрицы на столбец постоянных $C$ является общим решением СтЛВУ.
\end{itemize}
\textbf{Замечание.} \textit{Методом Эйлера мы находили ФСР СтЛВУ, однако мы не искали ФСР нормированную в точке. Подробнее поиск таких ФСР мы рассмотрим в матричном методе. Но мы можем получить фундаментальную матрицу нормированной ФСР в точке $t=t_0$ методом Эйлера. Для этого введем определение}\\\\
$\bullet$ \textit{ФСР называется \textbf{нормированной при $t = t_0$}, если ее $\FI(t_0) = E$.}\\\\
Если $X(t)$ --- решение задачи Коши $DX = AX$, $X|_{t=t_0} = \xi$, то $X(t_0) = \FI(t_0)\cdot C = \xi$. Следовательно, решение задачи Коши имеет вид $$X(t) = \FI(t)\cdot \FI^{-1}(t_0)\cdot\xi.\eqno(2)$$
Таким образом, полученная матрица $\FI(t)\cdot \FI^{-1}(t_0)$ будет являться \textbf{фундаментальной матрцией ФСР нормированной в точке $t=t_0$.} Поэтому ФСР полученная в методе Эйлера будет отличаться от ФСР полученной в матричном методе. Но матрица $\FI(t)\cdot \FI^{-1}(t_0)$ уже будет совпадать. То есть, домножив $\FI(t)$ на $\FI^{-1}(t_0)$, мы получим ФСР нормированную в точке $t=t_0$.\\\\
\textbf{Пример 5.}  Решить задачу Коши $X|_{t=t_0} = \xi$ для уравнения $$DX = AX, \quad A = \begin{pmatrix}
	2 & 0 & 0\\
	1 & 1 & 0\\
	1 & -1 & 3
\end{pmatrix},\quad t_0 = 0,\quad \xi =\begin{pmatrix}
1\\0\\2
\end{pmatrix}.$$
\textbf{Решение}. Вернемся к примеру 1. Фундаментальная матрица имеет вид $$\FI(t) = \begin{pmatrix}
	0 & e^{2t} & 0\\
	2e^t & e^{2t} & 0\\
	e^t & 0 & e^{3t}
\end{pmatrix}.$$ 
Для решения задачи Коши воспользуемся уравнением (2). Для этого нам необходимо найти обратную матрицу к фундаментальной. Можете найти ее известным Вам способом, я предлагаю расширить её единичной матрицей и привести методом Гаусса к частично-мономиальной:
$$\begin{pmatrix}
	0 & e^{2t} & 0 &\vline & 1 & 0 & 0\\
	2e^t & e^{2t} & 0 &\vline & 0 & 1 & 0\\
	e^t & 0 & e^{3t}&\vline & 0 & 0 & 1
\end{pmatrix}\sim \begin{pmatrix}
 1 & 0 & 0 & \vline & -\frac{e^{-t}}{2} & \frac{e^{-t}}{2} & 0\\
 0 & 1 & 0 & \vline & \frac{e^{-t}}{2} & 0 & 0\\
 0 & 0 & 1 & \vline & \frac{e^{-3t}}{2} & -\frac{e^{-3t}}{2} & e^{-3t}\\
\end{pmatrix}.$$
Теперь найдем произведние $\FI(t)\cdot \FI^{-1}(t_0)=\begin{pmatrix}
	e^{2(t-t_0)} & 0 & 0\\
	e^{2(t-t_0)}-e^{(t-t_0)} & e^{(t-t_0)} & 0\\
	\frac{1}{2}(e^{3(t-t_0)} - e^{(t-t_0)}) & \frac{1}{2}(e^{(t-t_0)} - e^{3(t-t_0)}) & e^{3(t-t_0)}
\end{pmatrix}.$ \\\\
Осталось умножить полученную матрицу на столбец $\xi$ при $t_0 = 0$ (подставить начальные условия):
$$X(t) = \begin{pmatrix}
	e^{2t}\\
	e^{2t} - e^t\\
	\frac{3}{2} e^{3t} - \frac{1}{2}e^t
\end{pmatrix}.$$
Полученный столбец является решением исходной задачи Коши.\\\\
\textbf{Ответ:} $X(t) = \begin{pmatrix}
	e^{2t}\\
	e^{2t} - e^t\\
	\frac{3}{2} e^{3t} - \frac{1}{2}e^t
\end{pmatrix}.$\\\\
Попробуйте найти решение задачи Коши уже известным из прошлого урока Вам методом, то есть найти из уравнения $(\FI(t)\cdot C)|_{t=t_0} = \xi$ коэффициенты $C_i$ и подставить в столбец $\FI(t)\cdot C$ и сравнить полученные решения.
\subsection*{Задачи для самостоятельного решения.}
Найти общие решения уравнений $DX = AX$, где
\begin{enumerate}
	\item $$A = \begin{pmatrix}
		7 & -12 & -2\\
		3 & -4 & 0\\
		-2 & 0 & -2
	\end{pmatrix};$$
\item $$A = \begin{pmatrix}
	4 & 6 & 0\\
	-3 & -5 & 0\\
	-3 & -6 & 1
\end{pmatrix};$$
\item $$A = \begin{pmatrix}
	1 & 0 & 0\\
	-1 & 1 & 2\\
	3 & 0 & 1
\end{pmatrix}.$$
\end{enumerate}
\end{document}